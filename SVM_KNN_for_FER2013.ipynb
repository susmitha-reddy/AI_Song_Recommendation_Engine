{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#classes of FER data set\n",
    "emotions = [\"happy\", \"neutral\", \"sad\",\"surprise\",\"fear\",\"disgust\",\"angry\"]\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "#Fetching the dat file which contains the pre trained model of landmark detection algorithm\n",
    "model = dlib.shape_predictor(\"C:\\\\Users\\\\Neha\\\\Desktop\\\\AIProject\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    # For all detected face instances individually\n",
    "    for k, d in enumerate(detections):\n",
    "        # Get facial landmarks with prediction model\n",
    "        shape = model(image, d)\n",
    "        xpoint = []\n",
    "        ypoint = []\n",
    "        for i in range(0, 68):\n",
    "            xpoint.append(float(shape.part(i).x))\n",
    "            ypoint.append(float(shape.part(i).y))\n",
    "\n",
    "        # Center points of both axis\n",
    "        xcenter = np.mean(xpoint)\n",
    "        ycenter = np.mean(ypoint)\n",
    "        # Calculate distance between particular points and center point\n",
    "        xdistcent = [(x-xcenter) for x in xpoint]\n",
    "        ydistcent = [(y-ycenter) for y in ypoint]\n",
    "\n",
    "        # Prevent divided by 0 value\n",
    "        if xpoint[11] == xpoint[14]:\n",
    "            angle_nose = 0\n",
    "        else:\n",
    "            # Point 14 is the tip of the nose, point 11 is the top of the nose brigde\n",
    "            angle_nose = int(math.atan((ypoint[11]-ypoint[14])/(xpoint[11]-xpoint[14]))*180/math.pi)\n",
    "\n",
    "        # Get offset by finding how the nose brigde should be rotated to become perpendicular to the horizontal plane\n",
    "        if angle_nose < 0:\n",
    "            angle_nose += 90\n",
    "        else:\n",
    "            angle_nose -= 90\n",
    "\n",
    "        landmarks = []\n",
    "        for cx, cy, x, y in zip(xdistcent, ydistcent, xpoint, ypoint):\n",
    "            # Add the coordinates relative to the centre of gravity\n",
    "            landmarks.append(cx)\n",
    "            landmarks.append(cy)\n",
    "\n",
    "            # Get the euclidean distance between each point and the centre point (the vector length)\n",
    "            meanar = np.asarray((ycenter,xcenter))\n",
    "            centpar = np.asarray((y,x))\n",
    "            dist = np.linalg.norm(centpar-meanar)\n",
    "\n",
    "            # Get the angle the vector describes relative to the image, corrected for the offset that the nosebrigde\n",
    "            # has when the face is not perfectly horizontal\n",
    "            if x == xcenter:\n",
    "                angle_relative = 0\n",
    "            else:\n",
    "                angle_relative = (math.atan(float(y-ycenter)/(x-xcenter))*180/math.pi) - angle_nose\n",
    "            landmarks.append(dist)\n",
    "            landmarks.append(angle_relative)\n",
    "\n",
    "    if len(detections) < 1:\n",
    "        # In case no case selected, print \"error\" values\n",
    "        landmarks = \"error\"\n",
    "    return landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the train and validation data set \n",
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_label = []\n",
    "    testing_data = []\n",
    "    testing_label = []\n",
    "    for emotion in emotions:\n",
    "        training_set, testing_set = get_files(emotion)\n",
    "        print(\"length:\", len(training_set))\n",
    "        #add data to training and testing dataset, and generate labels 0-4\n",
    "        for item in training_set:\n",
    "            #read image\n",
    "            img = cv2.imread(item)\n",
    "            #convert to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            clahe_img = clahe.apply(gray_img)\n",
    "            landmarks_vec = get_landmarks(clahe_img)\n",
    "\n",
    "            if landmarks_vec == \"error\":\n",
    "                pass\n",
    "            else:\n",
    "                training_data.append(landmarks_vec)\n",
    "                training_label.append(emotions.index(emotion))\n",
    "\n",
    "        for item in testing_set:\n",
    "            img = cv2.imread(item)\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            clahe_img = clahe.apply(gray_img)\n",
    "            landmarks_vec = get_landmarks(clahe_img)\n",
    "            if landmarks_vec == \"error\":\n",
    "                pass\n",
    "            else:\n",
    "                testing_data.append(landmarks_vec)\n",
    "                testing_label.append(emotions.index(emotion))\n",
    "\n",
    "    return training_data, training_label, testing_data, testing_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def get_files(emotion):\n",
    "    images = glob.glob(\"C:\\\\Users\\\\Neha\\\\Desktop\\\\AIProject\\\\FER\\\\%s\\\\*\" %emotion)\n",
    "    random.shuffle(images)\n",
    "    training_set = images[:int(len(images)*0.8)]   #get 80% of image files to be trained\n",
    "    testing_set = images[-int(len(images)*0.2):]   #get 20% of image files to be tested\n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 5772\n",
      "length: 3972\n",
      "length: 3864\n",
      "length: 2536\n",
      "length: 3277\n",
      "length: 348\n",
      "length: 3196\n",
      "14896\n",
      "14896\n"
     ]
    }
   ],
   "source": [
    "#Creating train and validation data set\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train_knn, y_train_knn, X_test_knn, y_test_knn = make_sets()\n",
    "print(len(X_train_knn))\n",
    "print(len(y_train_knn))\n",
    "X_train_knn_arr = np.array(X_train_knn)\n",
    "Y_train_knn_arr = np.array(y_train_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying standardisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_test_knn_arr = np.array(X_test_knn)\n",
    "Y_test_knn_arr = np.array(y_test_knn)\n",
    "X_train_knn_arr = scaler.fit_transform(X_train_knn_arr)\n",
    "X_test_knn_arr = scaler.transform(X_test_knn_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14896, 272)\n",
      "(14896,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_knn_arr.shape)\n",
    "print(Y_train_knn_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 23}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding best parameter using GridSearchCV\n",
    "clf_knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 30) }\n",
    "knn_gridcv = GridSearchCV(clf_knn, param_grid ,cv=10, refit = True,n_jobs= -1)\n",
    "knn_gridcv.fit(X_train_knn_arr,Y_train_knn_arr)\n",
    "knn_gridcv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44226845, 0.43824029, 0.44179743, 0.4445483 , 0.4474347 ,\n",
       "       0.44864397, 0.44884608, 0.45052429, 0.44931601, 0.45092716,\n",
       "       0.45347799, 0.45354443, 0.45441691, 0.45676626, 0.45582644,\n",
       "       0.45522277, 0.45670014, 0.45683482, 0.45629728, 0.45696842,\n",
       "       0.45797504, 0.45824349, 0.45965325, 0.45945227, 0.45770636,\n",
       "       0.45871325, 0.45737065, 0.45763906, 0.45757199])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = knn_gridcv.cv_results_['mean_test_score']\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69      1073\n",
      "           1       0.35      0.63      0.45       709\n",
      "           2       0.29      0.09      0.14       455\n",
      "           3       0.59      0.42      0.49       424\n",
      "           4       0.32      0.13      0.18       462\n",
      "           5       0.00      0.00      0.00        57\n",
      "           6       0.37      0.10      0.16       480\n",
      "\n",
      "    accuracy                           0.46      3660\n",
      "   macro avg       0.36      0.32      0.30      3660\n",
      "weighted avg       0.43      0.46      0.41      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "grid_predictin_random= knn_gridcv.predict(X_test_knn_arr)\n",
    "print(classification_report(Y_test_knn_arr,grid_predictin_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 5772\n",
      "length: 3972\n",
      "length: 3864\n",
      "length: 2536\n",
      "length: 3277\n",
      "length: 348\n",
      "length: 3196\n"
     ]
    }
   ],
   "source": [
    "#Creating train and test data set for SVM \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train, y_train, X_test, y_test = make_sets()\n",
    "#Applying standardization\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=1.4245532033758337, gamma=0.0014920502377871508 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1.4245532033758337, gamma=0.0014920502377871508, total=  39.5s\n",
      "[CV] C=1.4245532033758337, gamma=0.0014920502377871508 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1.4245532033758337, gamma=0.0014920502377871508, total=  34.8s\n",
      "[CV] C=1.4245532033758337, gamma=0.0014920502377871508 ...............\n",
      "[CV]  C=1.4245532033758337, gamma=0.0014920502377871508, total=  36.6s\n",
      "[CV] C=5.388970121123746, gamma=0.010485877666893474 .................\n",
      "[CV] .. C=5.388970121123746, gamma=0.010485877666893474, total=  48.8s\n",
      "[CV] C=5.388970121123746, gamma=0.010485877666893474 .................\n",
      "[CV] .. C=5.388970121123746, gamma=0.010485877666893474, total=  48.5s\n",
      "[CV] C=5.388970121123746, gamma=0.010485877666893474 .................\n",
      "[CV] .. C=5.388970121123746, gamma=0.010485877666893474, total=  48.6s\n",
      "[CV] C=9.001198957369, gamma=0.010711823154681908 ....................\n",
      "[CV] ..... C=9.001198957369, gamma=0.010711823154681908, total=  51.6s\n",
      "[CV] C=9.001198957369, gamma=0.010711823154681908 ....................\n",
      "[CV] ..... C=9.001198957369, gamma=0.010711823154681908, total=  52.7s\n",
      "[CV] C=9.001198957369, gamma=0.010711823154681908 ....................\n",
      "[CV] ..... C=9.001198957369, gamma=0.010711823154681908, total=  51.5s\n",
      "[CV] C=7.939585581286668, gamma=0.001597693599900346 .................\n",
      "[CV] .. C=7.939585581286668, gamma=0.001597693599900346, total=  33.4s\n",
      "[CV] C=7.939585581286668, gamma=0.001597693599900346 .................\n",
      "[CV] .. C=7.939585581286668, gamma=0.001597693599900346, total=  33.4s\n",
      "[CV] C=7.939585581286668, gamma=0.001597693599900346 .................\n",
      "[CV] .. C=7.939585581286668, gamma=0.001597693599900346, total=  33.8s\n",
      "[CV] C=7.786440215591567, gamma=0.002944085280686374 .................\n",
      "[CV] .. C=7.786440215591567, gamma=0.002944085280686374, total=  34.7s\n",
      "[CV] C=7.786440215591567, gamma=0.002944085280686374 .................\n",
      "[CV] .. C=7.786440215591567, gamma=0.002944085280686374, total=  35.5s\n",
      "[CV] C=7.786440215591567, gamma=0.002944085280686374 .................\n",
      "[CV] .. C=7.786440215591567, gamma=0.002944085280686374, total= 2.8min\n",
      "[CV] C=1.725228608965185, gamma=0.052498530589315154 .................\n",
      "[CV] .. C=1.725228608965185, gamma=0.052498530589315154, total=  59.5s\n",
      "[CV] C=1.725228608965185, gamma=0.052498530589315154 .................\n",
      "[CV] .. C=1.725228608965185, gamma=0.052498530589315154, total= 1.0min\n",
      "[CV] C=1.725228608965185, gamma=0.052498530589315154 .................\n",
      "[CV] .. C=1.725228608965185, gamma=0.052498530589315154, total=  57.8s\n",
      "[CV] C=4.067544170673031, gamma=0.009329584112336965 .................\n",
      "[CV] .. C=4.067544170673031, gamma=0.009329584112336965, total=  43.1s\n",
      "[CV] C=4.067544170673031, gamma=0.009329584112336965 .................\n",
      "[CV] .. C=4.067544170673031, gamma=0.009329584112336965, total=  45.5s\n",
      "[CV] C=4.067544170673031, gamma=0.009329584112336965 .................\n",
      "[CV] .. C=4.067544170673031, gamma=0.009329584112336965, total=  44.8s\n",
      "[CV] C=4.025065385029912, gamma=0.013285940313985526 .................\n",
      "[CV] .. C=4.025065385029912, gamma=0.013285940313985526, total=  52.2s\n",
      "[CV] C=4.025065385029912, gamma=0.013285940313985526 .................\n",
      "[CV] .. C=4.025065385029912, gamma=0.013285940313985526, total=  51.5s\n",
      "[CV] C=4.025065385029912, gamma=0.013285940313985526 .................\n",
      "[CV] .. C=4.025065385029912, gamma=0.013285940313985526, total=  54.0s\n",
      "[CV] C=10.453545302637405, gamma=0.0012378784993227543 ...............\n",
      "[CV]  C=10.453545302637405, gamma=0.0012378784993227543, total=  34.6s\n",
      "[CV] C=10.453545302637405, gamma=0.0012378784993227543 ...............\n",
      "[CV]  C=10.453545302637405, gamma=0.0012378784993227543, total=  35.5s\n",
      "[CV] C=10.453545302637405, gamma=0.0012378784993227543 ...............\n",
      "[CV]  C=10.453545302637405, gamma=0.0012378784993227543, total=  36.7s\n",
      "[CV] C=1.0552309397235429, gamma=0.002945822651438287 ................\n",
      "[CV] . C=1.0552309397235429, gamma=0.002945822651438287, total=  36.7s\n",
      "[CV] C=1.0552309397235429, gamma=0.002945822651438287 ................\n",
      "[CV] . C=1.0552309397235429, gamma=0.002945822651438287, total=  36.4s\n",
      "[CV] C=1.0552309397235429, gamma=0.002945822651438287 ................\n",
      "[CV] . C=1.0552309397235429, gamma=0.002945822651438287, total=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 23.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(),\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001B52F9B5670>,\n",
       "                                        'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001B52E867340>},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best parameter for tuning SVM\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)\n",
    "rnd_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=7.786440215591567, gamma=0.002944085280686374)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best hyperparameter\n",
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225450435992848"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best score in Training Data set\n",
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543571812802582"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of training data set\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the test data set\n",
    "def prep_test_set():\n",
    "\n",
    "    testing_data = []\n",
    "    testing_label = []\n",
    "    for emotion in emotions:\n",
    "        images = glob.glob(\"C:\\\\Users\\\\Neha\\\\Desktop\\\\AIProject\\\\archive\\\\test\\\\%s\\\\*\" %emotion)\n",
    "        \n",
    "        #random.shuffle(images)\n",
    "        train_set = images[:]\n",
    "        print(len(train_set))\n",
    "        #add data to training and testing dataset, and generate labels 0-4\n",
    "        for item in train_set:\n",
    "            #read image\n",
    "            img = cv2.imread(item)\n",
    "            #convert to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            clahe_img = clahe.apply(gray_img)\n",
    "            landmarks_vec = get_landmarks(clahe_img)\n",
    "\n",
    "            if landmarks_vec == \"error\":\n",
    "                pass\n",
    "            else:\n",
    "                testing_data.append(landmarks_vec)\n",
    "                testing_label.append(emotions.index(emotion))\n",
    "\n",
    "        \n",
    "    return  testing_data, testing_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1774\n",
      "1233\n",
      "1247\n",
      "831\n",
      "1024\n",
      "111\n",
      "958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5357987529563535"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for accuracy for test data set\n",
    "X_test_org, y_test_org = prep_test_set()\n",
    "np_X_test_org = np.array(X_test_org)\n",
    "np_y_test_org = np.array(y_test_org)\n",
    "X_test_org_scaled = scaler.transform(np_X_test_org)\n",
    "\n",
    "y_test_pred = rnd_search_cv.best_estimator_.predict(X_test_org_scaled)\n",
    "accuracy_score(np_y_test_org, y_test_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
